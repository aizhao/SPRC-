# é—¨æ§èåˆæœºåˆ¶ (Gated Fusion Mechanism)

## ğŸ“‹ æ¦‚è¿°

è¿™æ˜¯å¯¹SPRCæ¨¡å‹çš„ä¸€ä¸ªé‡è¦æ”¹è¿›ï¼Œé€šè¿‡**é—¨æ§èåˆæœºåˆ¶**è®©æ–‡æœ¬èƒ½å¤Ÿ**é€‰æ‹©æ€§åœ°ä¿®æ”¹å›¾åƒç‰¹å¾**ï¼Œè€Œä¸æ˜¯ç®€å•åœ°æ‹¼æ¥ã€‚

## ğŸ¯ æ ¸å¿ƒæ€æƒ³

### é—®é¢˜
åŸå§‹SPRCç®€å•åœ°å°†query tokenså’Œtext tokensæ‹¼æ¥åé€å…¥Q-Formerï¼š
```python
# åŸå§‹æ–¹æ³•ï¼šç®€å•æ‹¼æ¥
attention_mask = torch.cat([query_atts, text_tokens.attention_mask], dim=1)
fusion_output = self.Qformer.bert(
    text_tokens.input_ids,
    query_embeds=query_tokens,
    attention_mask=attention_mask,
    encoder_hidden_states=image_embeds,  # åŸå§‹å›¾åƒç‰¹å¾
    ...
)
```

**ç¼ºç‚¹ï¼š**
- æ–‡æœ¬å’Œå›¾åƒç‰¹å¾æ²¡æœ‰æ˜¾å¼äº¤äº’
- æ— æ³•å»ºæ¨¡"ä¿®æ”¹"çš„è¯­ä¹‰ï¼ˆä¾‹å¦‚"æ¢æˆçº¢è‰²"ï¼‰
- Q-Formeréœ€è¦éšå¼å­¦ä¹ å¦‚ä½•èåˆ

### è§£å†³æ–¹æ¡ˆ
ä½¿ç”¨**é—¨æ§èåˆ**è®©æ–‡æœ¬æŒ‡å¯¼å›¾åƒç‰¹å¾çš„ä¿®æ”¹ï¼š

```python
# æ–°æ–¹æ³•ï¼šé—¨æ§èåˆ
if self.use_gated_fusion:
    # 1. è·å–æ–‡æœ¬è¡¨ç¤º
    text_embeds = self.Qformer.bert.embeddings(input_ids=text_tokens.input_ids)
    
    # 2. åº”ç”¨é—¨æ§èåˆ
    image_embeds_fused = self.gated_fusion(image_embeds, text_embeds)
    
    # 3. ä½¿ç”¨èåˆåçš„ç‰¹å¾
    fusion_output = self.Qformer.bert(
        ...,
        encoder_hidden_states=image_embeds_fused,  # èåˆåçš„ç‰¹å¾
        ...
    )
```

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### GatedFusionModule æ¶æ„

```
è¾“å…¥: image_feat (B, N, D), text_feat (B, M, D)

1. æ–‡æœ¬å…¨å±€è¡¨ç¤º
   text_global = mean_pool(text_feat)  # (B, 1, D)
   text_global = expand(text_global)    # (B, N, D)

2. é—¨æ§ä¿¡å· (å†³å®šä¿®æ”¹ç¨‹åº¦)
   concat = [image_feat; text_global]   # (B, N, 2D)
   gate = sigmoid(MLP(concat))          # (B, N, D) âˆˆ [0, 1]

3. ä¿®æ”¹å‘é‡ (å†³å®šä¿®æ”¹æ–¹å‘)
   delta = tanh(MLP(text_global))       # (B, N, D) âˆˆ [-1, 1]

4. èåˆè¾“å‡º
   fused = image_feat + Î± * gate * delta

è¾“å‡º: fused_feat (B, N, D)
```

### æ•°å­¦å…¬å¼

$$
\begin{align}
\mathbf{t}_{\text{global}} &= \text{MeanPool}(\mathbf{T}) \\
\mathbf{g} &= \sigma(\text{MLP}_g([\mathbf{I}; \mathbf{t}_{\text{global}}])) \\
\boldsymbol{\delta} &= \tanh(\text{MLP}_\delta(\mathbf{t}_{\text{global}})) \\
\mathbf{F} &= \mathbf{I} + \alpha \odot \mathbf{g} \odot \boldsymbol{\delta}
\end{align}
$$

å…¶ä¸­ï¼š
- $\mathbf{I}$: å›¾åƒç‰¹å¾ (B, N, D)
- $\mathbf{T}$: æ–‡æœ¬ç‰¹å¾ (B, M, D)
- $\mathbf{g}$: é—¨æ§ä¿¡å·ï¼Œæ§åˆ¶ä¿®æ”¹ç¨‹åº¦
- $\boldsymbol{\delta}$: ä¿®æ”¹å‘é‡ï¼Œæ§åˆ¶ä¿®æ”¹æ–¹å‘
- $\alpha$: å¯å­¦ä¹ çš„ç¼©æ”¾å› å­
- $\odot$: é€å…ƒç´ ä¹˜æ³•

### å…³é”®è®¾è®¡

1. **é—¨æ§æœºåˆ¶**
   - `gate âˆˆ [0, 1]`ï¼š0è¡¨ç¤ºä¸ä¿®æ”¹ï¼Œ1è¡¨ç¤ºå®Œå…¨åº”ç”¨ä¿®æ”¹
   - è®©æ¨¡å‹å­¦ä¹ å“ªäº›ä½ç½®éœ€è¦ä¿®æ”¹

2. **ä¿®æ”¹å‘é‡**
   - `delta âˆˆ [-1, 1]`ï¼šè¡¨ç¤ºä¿®æ”¹çš„æ–¹å‘å’Œå¹…åº¦
   - ç”±æ–‡æœ¬æŒ‡å¯¼ç”Ÿæˆ

3. **æ®‹å·®è¿æ¥**
   - `Î±`ï¼šå¯å­¦ä¹ çš„ç¼©æ”¾å› å­ï¼Œåˆå§‹åŒ–ä¸º0.5
   - ä¿è¯è®­ç»ƒç¨³å®šæ€§

4. **LayerNorm + Dropout**
   - é˜²æ­¢è¿‡æ‹Ÿåˆ
   - æå‡è®­ç»ƒç¨³å®šæ€§

## ğŸ“Š ä¼˜åŠ¿

### 1. **æ˜¾å¼å»ºæ¨¡ä¿®æ”¹è¯­ä¹‰**
```
æ–‡æœ¬: "change the color to red"
â†’ é—¨æ§ä¼šå…³æ³¨é¢œè‰²ç›¸å…³çš„å›¾åƒåŒºåŸŸ
â†’ ä¿®æ”¹å‘é‡ä¼šæŒ‡å‘"çº¢è‰²"çš„ç‰¹å¾ç©ºé—´
```

### 2. **é€‰æ‹©æ€§ä¿®æ”¹**
```
é—¨æ§å€¼é«˜ â†’ è¯¥ä½ç½®éœ€è¦å¤§å¹…ä¿®æ”¹
é—¨æ§å€¼ä½ â†’ è¯¥ä½ç½®ä¿æŒä¸å˜
```

### 3. **å¯è§£é‡Šæ€§**
- å¯ä»¥å¯è§†åŒ–é—¨æ§å›¾ï¼Œçœ‹æ¨¡å‹å…³æ³¨å“ªé‡Œ
- å¯ä»¥åˆ†æä¿®æ”¹å‘é‡ï¼Œç†è§£ä¿®æ”¹æ–¹å‘

### 4. **è®­ç»ƒç¨³å®š**
- æ®‹å·®è¿æ¥ä¿è¯æ¢¯åº¦æµåŠ¨
- åˆå§‹æ—¶Î±=0.5ï¼Œæ¨¡å‹é€æ¸å­¦ä¹ ä¿®æ”¹ç¨‹åº¦

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. è®­ç»ƒæ—¶å¯ç”¨

é—¨æ§èåˆé»˜è®¤å¯ç”¨ï¼Œæ— éœ€é¢å¤–é…ç½®ï¼š

```bash
python src/blip_fine_tune_2.py \
    --dataset CIRR \
    --blip-model-name blip2_cir_align_prompt \
    --backbone pretrain \
    --num-epochs 10 \
    --batch-size 64 \
    --learning-rate 1e-5 \
    --loss-align 0.4 \
    --loss-rtc 0.4 \
    --validation-frequency 1 \
    --save-training \
    --save-best \
    --target-ratio 1.25 \
    --transform targetpad
```

### 2. ç¦ç”¨é—¨æ§èåˆï¼ˆå¯¹æ¯”å®éªŒï¼‰

å¦‚æœæƒ³ç¦ç”¨é—¨æ§èåˆè¿›è¡Œå¯¹æ¯”å®éªŒï¼Œä¿®æ”¹æ¨¡å‹ä»£ç ï¼š

```python
# åœ¨ blip2_qformer_cir_align_prompt.py çš„ __init__ ä¸­
self.use_gated_fusion = False  # æ”¹ä¸º False
```

### 3. æµ‹è¯•å®ç°

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯å®ç°ï¼š

```bash
python test_gated_fusion.py
```

## ğŸ“ˆ é¢„æœŸæ•ˆæœ

### æ€§èƒ½æå‡
- **Baseline (æ— é—¨æ§èåˆ)**: ~70% mean(R@5+R_s@1)
- **é¢„æœŸ (æœ‰é—¨æ§èåˆ)**: ~72-75% mean(R@5+R_s@1)

### æ”¶æ•›é€Ÿåº¦
- æ›´å¿«çš„æ”¶æ•›ï¼ˆfewer epochs to reach best performanceï¼‰
- æ›´ç¨³å®šçš„è®­ç»ƒæ›²çº¿

### æ³›åŒ–èƒ½åŠ›
- æ›´å¥½çš„è·¨åŸŸæ³›åŒ–ï¼ˆCIRR â†’ FashionIQï¼‰
- å¯¹å¤æ‚æ–‡æœ¬æè¿°çš„ç†è§£æ›´å¥½

## ğŸ” æ¶ˆèå®éªŒ

å»ºè®®è¿›è¡Œä»¥ä¸‹æ¶ˆèå®éªŒæ¥éªŒè¯å„ç»„ä»¶çš„ä½œç”¨ï¼š

### 1. é—¨æ§ vs æ— é—¨æ§
```python
# å®éªŒ1ï¼šå®Œæ•´é—¨æ§èåˆ
self.use_gated_fusion = True

# å®éªŒ2ï¼šæ— é—¨æ§èåˆï¼ˆbaselineï¼‰
self.use_gated_fusion = False
```

### 2. ä¸åŒçš„èåˆç­–ç•¥
```python
# ç­–ç•¥Aï¼šé—¨æ§èåˆï¼ˆå½“å‰ï¼‰
fused = image + Î± * gate * delta

# ç­–ç•¥Bï¼šç®€å•åŠ æ³•
fused = image + Î± * delta

# ç­–ç•¥Cï¼šåŠ æƒå¹³å‡
fused = gate * (image + delta) + (1 - gate) * image
```

### 3. ä¸åŒçš„Î±åˆå§‹åŒ–
```python
# åˆå§‹åŒ–1ï¼šÎ± = 0.5ï¼ˆå½“å‰ï¼‰
self.alpha = nn.Parameter(torch.ones(1) * 0.5)

# åˆå§‹åŒ–2ï¼šÎ± = 0.1ï¼ˆæ›´ä¿å®ˆï¼‰
self.alpha = nn.Parameter(torch.ones(1) * 0.1)

# åˆå§‹åŒ–3ï¼šÎ± = 1.0ï¼ˆæ›´æ¿€è¿›ï¼‰
self.alpha = nn.Parameter(torch.ones(1) * 1.0)
```

## ğŸ“ å®ç°ç»†èŠ‚

### å‚æ•°é‡
```
GatedFusionModuleå‚æ•°é‡ï¼ˆhidden_size=768ï¼‰:
- gate_net: 768*2 * 768 + 768 * 768 â‰ˆ 1.77M
- delta_net: 768 * 768 + 768 * 768 â‰ˆ 1.18M
- alpha: 1
æ€»è®¡: ~2.95M å‚æ•°
```

### è®¡ç®—å¤æ‚åº¦
```
å‰å‘ä¼ æ’­ï¼ˆbatch_size=B, num_tokens=N, hidden_size=Dï¼‰:
- text pooling: O(B * M * D)
- gate computation: O(B * N * 2D * D) = O(2BNDÂ²)
- delta computation: O(B * N * D * D) = O(BNDÂ²)
- fusion: O(B * N * D)
æ€»è®¡: O(3BNDÂ²)
```

ç›¸æ¯”åŸå§‹Q-Formerçš„è®¡ç®—é‡ï¼ˆO(BNÂ²D)ï¼‰ï¼Œå¢åŠ çš„å¼€é”€å¾ˆå°ã€‚

## ğŸ› è°ƒè¯•æŠ€å·§

### 1. æ£€æŸ¥é—¨æ§å€¼åˆ†å¸ƒ
```python
# åœ¨forwardä¸­æ·»åŠ 
if self.training and random.random() < 0.01:  # 1%æ¦‚ç‡æ‰“å°
    gate_mean = gate.mean().item()
    gate_std = gate.std().item()
    print(f"Gate - mean: {gate_mean:.3f}, std: {gate_std:.3f}")
```

### 2. æ£€æŸ¥ä¿®æ”¹å¹…åº¦
```python
# åœ¨forwardä¸­æ·»åŠ 
if self.training and random.random() < 0.01:
    diff = (image_embeds_fused - image_embeds).abs().mean().item()
    print(f"Fusion diff: {diff:.6f}")
```

### 3. å¯è§†åŒ–é—¨æ§å›¾
```python
# ä¿å­˜é—¨æ§å›¾ç”¨äºå¯è§†åŒ–
import matplotlib.pyplot as plt

gate_map = gate[0].mean(dim=-1).cpu().numpy()  # (N,)
plt.figure(figsize=(8, 8))
plt.imshow(gate_map.reshape(16, 16), cmap='hot')
plt.colorbar()
plt.title("Gate Activation Map")
plt.savefig("gate_map.png")
```

## ğŸ“š ç›¸å…³å·¥ä½œ

è¿™ä¸ªå®ç°å—åˆ°ä»¥ä¸‹å·¥ä½œçš„å¯å‘ï¼š

1. **Gated Fusion** (Arevalo et al., 2017)
   - ç”¨äºå¤šæ¨¡æ€èåˆçš„é—¨æ§æœºåˆ¶

2. **FiLM** (Perez et al., 2018)
   - Feature-wise Linear Modulation
   - ç”¨æ¡ä»¶ä¿¡æ¯è°ƒåˆ¶ç‰¹å¾

3. **TIRG** (Vo et al., 2019)
   - Text-Image Residual Gating
   - CIRä»»åŠ¡çš„ç»å…¸æ–¹æ³•

## ğŸ“ å¼•ç”¨

å¦‚æœè¿™ä¸ªå®ç°å¯¹ä½ çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨ï¼š

```bibtex
@misc{sprc_gated_fusion_2024,
  title={Gated Fusion for Composed Image Retrieval},
  author={Your Name},
  year={2024},
  note={Implementation based on SPRC}
}
```

## ğŸ“§ è”ç³»

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»ï¼š
- Email: 2754746505@qq.com
- GitHub: [SPRC Repository]

---

**æœ€åæ›´æ–°**: 2024-11-21
**ç‰ˆæœ¬**: 1.0
