# æ­¥éª¤2å®Œæˆï¼šæ•°æ®åŠ è½½å™¨ä¿®æ”¹

## âœ… å®Œæˆå†…å®¹

### 1. ä¿®æ”¹CIRRDatasetç±»

**æ–‡ä»¶**: `/home/caoyu/mnt/zhaoai/SPRC/src/data_utils.py`

#### æ–°å¢åŠŸèƒ½:

**a) æ·»åŠ box_fileå‚æ•°** (ç¬¬214è¡Œ)
```python
def __init__(self, split: str, mode: str, preprocess: callable, box_file: str = None):
```

**b) åŠ è½½bounding boxæ•°æ®** (ç¬¬244-258è¡Œ)
```python
# load bounding box data if provided
self.boxes = {}
self.use_boxes = False
if box_file is not None:
    import os
    box_path = base_path / box_file if not os.path.isabs(box_file) else box_file
    if os.path.exists(box_path):
        with open(box_path, 'r') as f:
            self.boxes = json.load(f)
        self.use_boxes = True
        print(f"Loaded bounding boxes from {box_path} ({len(self.boxes)} images)")
    else:
        print(f"Warning: box_file {box_path} not found, boxes will not be used")
```

**c) è¿”å›boxesæ•°æ®** (ç¬¬274-280è¡Œ)
```python
# get bounding boxes if available
if self.use_boxes:
    ref_boxes = self.boxes.get(reference_name, [])
    tgt_boxes = self.boxes.get(target_hard_name, [])
    return reference_image, target_image, rel_caption, ref_boxes, tgt_boxes
else:
    return reference_image, target_image, rel_caption
```

**d) æ·»åŠ è¾…åŠ©æ–¹æ³•** (ç¬¬311-319è¡Œ)
```python
def get_image_size(self, image_name: str):
    """Get the original size of an image"""
    image_path = base_path / 'cirr_dataset' / self.name_to_relpath[image_name]
    with PIL.Image.open(image_path) as img:
        return img.size
```

### 2. ä¿®æ”¹è®­ç»ƒè„šæœ¬

**æ–‡ä»¶**: `/home/caoyu/mnt/zhaoai/SPRC/src/blip_fine_tune_2.py`

#### æ–°å¢åŠŸèƒ½:

**a) æ•°æ®é›†åˆå§‹åŒ–æ—¶ä¼ é€’box_file** (ç¬¬249-257è¡Œ)
```python
box_file = kwargs.get('box_file', None)
relative_val_dataset = CIRRDataset('val', 'relative', preprocess, box_file=box_file)
classic_val_dataset = CIRRDataset('val', 'classic', preprocess)
relative_train_dataset = CIRRDataset('train', 'relative', preprocess, box_file=box_file)
```

**b) è®­ç»ƒå¾ªç¯å¤„ç†å¯å˜é•¿åº¦batch** (ç¬¬287-293è¡Œ)
```python
for idx, batch_data in enumerate(train_bar):
    # å¤„ç†å¯å˜é•¿åº¦çš„batchæ•°æ®ï¼ˆæœ‰æ— boxesï¼‰
    if len(batch_data) == 5:
        reference_images, target_images, captions, ref_boxes, tgt_boxes = batch_data
    else:
        reference_images, target_images, captions = batch_data
        ref_boxes, tgt_boxes = None, None
```

**c) å‰å‘ä¼ æ’­æ—¶ä¼ é€’boxes** (ç¬¬299-300è¡Œ)
```python
loss_dict = blip_model({"image":reference_images, "target":target_images, "text_input":captions, 
                       "region_boxes": ref_boxes, "target_region_boxes": tgt_boxes})
```

**d) æ·»åŠ å‘½ä»¤è¡Œå‚æ•°** (ç¬¬401è¡Œ)
```python
parser.add_argument("--box-file", type=str, default=None, help="Path to JSON file containing bounding boxes")
```

**e) ä¼ é€’åˆ°è®­ç»ƒé…ç½®** (ç¬¬435è¡Œ)
```python
"box_file": args.box_file,
```

### 3. åˆ›å»ºBoxç”Ÿæˆå·¥å…·

**æ–‡ä»¶**: `/home/caoyu/mnt/zhaoai/SPRC/generate_boxes_example.py`

æä¾›ä¸‰ç§æ–¹å¼ç”Ÿæˆboxes:
1. **éšæœºboxes** - ç”¨äºå¿«é€Ÿæµ‹è¯•
2. **YOLOæ£€æµ‹** - ä½¿ç”¨ç›®æ ‡æ£€æµ‹æ¨¡å‹
3. **æ˜¾è‘—æ€§æ£€æµ‹** - ä½¿ç”¨OpenCVæ˜¾è‘—æ€§æ£€æµ‹

## ğŸ“Š Boxæ•°æ®æ ¼å¼

### JSONæ–‡ä»¶æ ¼å¼
```json
{
    "image_name_1": [
        [0.1, 0.1, 0.5, 0.5],  // box1: [x1, y1, x2, y2]
        [0.6, 0.6, 0.9, 0.9]   // box2: [x1, y1, x2, y2]
    ],
    "image_name_2": [
        [0.2, 0.2, 0.8, 0.8]
    ],
    "image_name_3": []  // æ²¡æœ‰boxes
}
```

### åæ ‡è¯´æ˜
- **æ ¼å¼**: `[x1, y1, x2, y2]`
- **å½’ä¸€åŒ–**: æ‰€æœ‰åæ ‡å½’ä¸€åŒ–åˆ° `[0, 1]` èŒƒå›´
- **å«ä¹‰**: 
  - `(x1, y1)`: å·¦ä¸Šè§’åæ ‡
  - `(x2, y2)`: å³ä¸‹è§’åæ ‡

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### æ–¹æ³•1: ç”Ÿæˆéšæœºboxesï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰

```bash
cd /home/caoyu/mnt/zhaoai/SPRC

# è¿è¡Œç”Ÿæˆè„šæœ¬
python generate_boxes_example.py
# é€‰æ‹©é€‰é¡¹ 1ï¼ˆéšæœºboxesï¼‰

# ä½¿ç”¨ç”Ÿæˆçš„boxesè®­ç»ƒ
cd src
python blip_fine_tune_2.py \
    --dataset CIRR \
    --blip-model-name blip2_cir_align_prompt \
    --use-region-loss \
    --box-file ../cirr_boxes_random.json \
    --loss-region 0.5 \
    --batch-size 128 \
    --num-epochs 10 \
    --save-training
```

### æ–¹æ³•2: ä½¿ç”¨YOLOç”Ÿæˆboxes

```bash
# å®‰è£…ä¾èµ–
pip install ultralytics

# è¿è¡Œç”Ÿæˆè„šæœ¬
python generate_boxes_example.py
# é€‰æ‹©é€‰é¡¹ 2ï¼ˆYOLOæ£€æµ‹ï¼‰

# è®­ç»ƒ
cd src
python blip_fine_tune_2.py \
    --dataset CIRR \
    --blip-model-name blip2_cir_align_prompt \
    --use-region-loss \
    --box-file ../cirr_boxes_yolo.json \
    --loss-region 0.5 \
    --save-training
```

### æ–¹æ³•3: ä½¿ç”¨æ˜¾è‘—æ€§æ£€æµ‹

```bash
# å®‰è£…ä¾èµ–
pip install opencv-python opencv-contrib-python

# è¿è¡Œç”Ÿæˆè„šæœ¬
python generate_boxes_example.py
# é€‰æ‹©é€‰é¡¹ 3ï¼ˆæ˜¾è‘—æ€§æ£€æµ‹ï¼‰

# è®­ç»ƒ
cd src
python blip_fine_tune_2.py \
    --dataset CIRR \
    --blip-model-name blip2_cir_align_prompt \
    --use-region-loss \
    --box-file ../cirr_boxes_saliency.json \
    --loss-region 0.5 \
    --save-training
```

### æ–¹æ³•4: ä¸ä½¿ç”¨boxesï¼ˆæ ‡å‡†è®­ç»ƒï¼‰

```bash
cd src
python blip_fine_tune_2.py \
    --dataset CIRR \
    --blip-model-name blip2_cir_align_prompt \
    --save-training
```

## ğŸ§ª æµ‹è¯•æ•°æ®åŠ è½½å™¨

åˆ›å»ºæµ‹è¯•è„šæœ¬éªŒè¯æ•°æ®åŠ è½½:

```python
# test_dataloader.py
import sys
sys.path.insert(0, './src')

from data_utils import CIRRDataset, targetpad_transform

# æµ‹è¯•ä¸å¸¦boxes
print("æµ‹è¯•1: ä¸å¸¦boxes")
dataset = CIRRDataset('train', 'relative', targetpad_transform(1.25, 224))
sample = dataset[0]
print(f"  è¿”å›å€¼æ•°é‡: {len(sample)}")
print(f"  ç±»å‹: {[type(s) for s in sample]}")

# æµ‹è¯•å¸¦boxes
print("\næµ‹è¯•2: å¸¦boxesï¼ˆéšæœºï¼‰")
dataset_with_boxes = CIRRDataset('train', 'relative', targetpad_transform(1.25, 224), 
                                 box_file='cirr_boxes_random.json')
sample = dataset_with_boxes[0]
print(f"  è¿”å›å€¼æ•°é‡: {len(sample)}")
if len(sample) == 5:
    ref_img, tgt_img, caption, ref_boxes, tgt_boxes = sample
    print(f"  å‚è€ƒå›¾åƒboxes: {ref_boxes}")
    print(f"  ç›®æ ‡å›¾åƒboxes: {tgt_boxes}")
```

## ğŸ“ å®Œæ•´è®­ç»ƒç¤ºä¾‹

```bash
#!/bin/bash

# æ­¥éª¤1: ç”Ÿæˆboxesï¼ˆå¯é€‰ï¼‰
echo "ç”Ÿæˆbounding boxes..."
python generate_boxes_example.py

# æ­¥éª¤2: è¿è¡Œæµ‹è¯•
echo "æµ‹è¯•åŠŸèƒ½..."
python test_roi_align.py

# æ­¥éª¤3: è®­ç»ƒï¼ˆä¸ä½¿ç”¨region lossï¼‰
echo "é˜¶æ®µ1: æ ‡å‡†è®­ç»ƒ..."
cd src
python blip_fine_tune_2.py \
    --dataset CIRR \
    --blip-model-name blip2_cir_align_prompt \
    --backbone pretrain \
    --num-epochs 30 \
    --batch-size 128 \
    --learning-rate 2e-6 \
    --loss-align 0.4 \
    --loss-rtc 0.4 \
    --save-training \
    --save-best

# æ­¥éª¤4: å¾®è°ƒï¼ˆä½¿ç”¨region lossï¼‰
echo "é˜¶æ®µ2: å¯ç”¨region losså¾®è°ƒ..."
python blip_fine_tune_2.py \
    --dataset CIRR \
    --blip-model-name blip2_cir_align_prompt \
    --backbone pretrain \
    --num-epochs 20 \
    --batch-size 128 \
    --learning-rate 5e-7 \
    --loss-align 0.4 \
    --loss-rtc 0.4 \
    --use-region-loss \
    --box-file ../cirr_boxes_random.json \
    --loss-region 0.5 \
    --save-training \
    --save-best

echo "è®­ç»ƒå®Œæˆï¼"
```

## ğŸ” æ•°æ®æµç¨‹å›¾

```
è®­ç»ƒæ•°æ®æµç¨‹:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CIRR Dataset   â”‚
â”‚  (with boxes)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€ box_fileå‚æ•°
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CIRRDataset.__init__()         â”‚
â”‚  - åŠ è½½triplets                  â”‚
â”‚  - åŠ è½½boxes (å¦‚æœæä¾›)          â”‚
â”‚  - self.use_boxes = True/False  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CIRRDataset.__getitem__()      â”‚
â”‚  - åŠ è½½å›¾åƒ                      â”‚
â”‚  - å¦‚æœuse_boxes:               â”‚
â”‚    è¿”å› (img, tgt, cap, boxes)  â”‚
â”‚  - å¦åˆ™:                        â”‚
â”‚    è¿”å› (img, tgt, cap)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DataLoader                     â”‚
â”‚  - batchåŒ–æ•°æ®                   â”‚
â”‚  - collate_fnå¤„ç†                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è®­ç»ƒå¾ªç¯                        â”‚
â”‚  - æ£€æŸ¥batché•¿åº¦                 â”‚
â”‚  - æå–boxes (å¦‚æœæœ‰)            â”‚
â”‚  - ä¼ é€’ç»™æ¨¡å‹                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model.forward()                â”‚
â”‚  - å¦‚æœæœ‰boxesä¸”use_region_loss  â”‚
â”‚    è®¡ç®—region loss              â”‚
â”‚  - è¿”å›æ‰€æœ‰losses                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. Boxæ–‡ä»¶è·¯å¾„
- å¯ä»¥ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºSPRCæ ¹ç›®å½•ï¼‰
- å¯ä»¥ä½¿ç”¨ç»å¯¹è·¯å¾„
- å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¼šæ‰“å°è­¦å‘Šä½†ä¸ä¼šæŠ¥é”™

### 2. å†…å­˜è€ƒè™‘
- Boxesæ•°æ®ä¼šå®Œå…¨åŠ è½½åˆ°å†…å­˜
- å¯¹äºå¤§æ•°æ®é›†ï¼Œè€ƒè™‘ä½¿ç”¨æŒ‰éœ€åŠ è½½

### 3. å…¼å®¹æ€§
- ä¸æä¾›box_fileæ—¶ï¼Œå®Œå…¨å‘åå…¼å®¹
- æä¾›box_fileä½†æŸäº›å›¾åƒæ²¡æœ‰boxesæ—¶ï¼Œè¿”å›ç©ºåˆ—è¡¨

### 4. æ€§èƒ½
- åŠ è½½boxesä¸ä¼šæ˜¾è‘—å½±å“æ•°æ®åŠ è½½é€Ÿåº¦
- RoI Alignè®¡ç®—ä¼šå¢åŠ çº¦10-15%çš„è®­ç»ƒæ—¶é—´

## ğŸ“š ç›¸å…³æ–‡ä»¶

- **æ•°æ®åŠ è½½å™¨**: `src/data_utils.py`
- **è®­ç»ƒè„šæœ¬**: `src/blip_fine_tune_2.py`
- **Boxç”Ÿæˆå·¥å…·**: `generate_boxes_example.py`
- **æµ‹è¯•è„šæœ¬**: `test_roi_align.py`
- **ä½¿ç”¨æ–‡æ¡£**: `ROI_ALIGN_USAGE.md`

## âœ¨ æ€»ç»“

æ­¥éª¤2å·²å®Œæˆï¼ç°åœ¨ä½ å¯ä»¥:

âœ… **å·²å®ç°çš„åŠŸèƒ½**:
1. æ•°æ®åŠ è½½å™¨æ”¯æŒbounding boxes
2. è®­ç»ƒè„šæœ¬è‡ªåŠ¨å¤„ç†æœ‰æ— boxesçš„æƒ…å†µ
3. æä¾›å¤šç§boxç”Ÿæˆæ–¹å¼
4. å®Œå…¨å‘åå…¼å®¹

ğŸ¯ **ä¸‹ä¸€æ­¥**:
1. ç”Ÿæˆå®é™…çš„bounding boxæ•°æ®
2. è¿è¡Œå®Œæ•´è®­ç»ƒæµç¨‹
3. è¯„ä¼°æ€§èƒ½æå‡

ğŸ’¡ **å¿«é€Ÿå¼€å§‹**:
```bash
# ç”Ÿæˆæµ‹è¯•boxes
python generate_boxes_example.py

# è¿è¡Œæµ‹è¯•
python test_roi_align.py

# å¼€å§‹è®­ç»ƒ
cd src
python blip_fine_tune_2.py --dataset CIRR --use-region-loss --box-file ../cirr_boxes_random.json --save-training
```

---

**å®Œæˆæ—¥æœŸ**: 2025-11-18  
**çŠ¶æ€**: âœ… å®Œæˆ
